<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="yanxia">
  <title>Yan Xia's Homepage</title>

  <!-- CSS  -->
  <link href="./files/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./images/TUM_logo3.png">
<script type="text/javascript" src="./files/jquery-1.12.4.min.js.下载"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://Yan-Xia.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://Yan-Xia.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#publications">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#preprints">Preprints</a></li> 
          <!--<li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#projects">Projects</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#activities">Activities</a></li>
          <!--<li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#education">Education</a></li>-->
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#internship">Internship</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#awards">Awards</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#demos">Demos</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>
  

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="./images/YanXia.JPG">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name">Yan Xia (夏彦)</h5>

        <hr>
        
        <h6 class="profile-link"><strong>Ph.D. Candidate at TUM, </strong> <a href="https://www.tum.de/en/"><strong>Chair of Ph</strong></a></h6>
        <!-- <h6 class="profile-link"><a href="https://www.in.tum.de/startseite/">Fakultät für Informatik</a></h6> -->
        <!-- <h6 class="profile-link"><a href="https://www.in.tum.de/i06/home/">Chair of Robotics, AI and Real-time Systems</a></h6> -->
        <h6 class="profile-link"><a href="https://www.tum.de/en/">Technical University of Munich, Munich, Germany 85748</a></h6>
        <h6 class="profile-link">Email: yan.xia@tum.de</h6>
        
        <h1></h1>
        
        <a href="https://scholar.google.com/citations?user=O7qS9DkAAAAJ&hl=en" target="_blank"><img class="responsive-img social-photo " src="./images/google_scholar.jpg"></a>
        
        <a href="https://github.com/HuCaoFighting" target="_blank"><img class="responsive-img social-photo " src="./images/github.jpg"></a>

        <!--<a href="./files/HuCao_CV.pdf" target="_blank"><img class="responsive-img social-photo " src="./images/cv.png"></a>-->

        <!--<a href="./images/Wechat_QR_code.jpg" target="_blank"><img class="responsive-img social-photo " src="./images/wechat.png"></a>-->

        <!--<a href="https://www.zhihu.com/people/flyyoung-68" target="_blank"><img class="responsive-img social-photo " src="./images/zhihu1.png"></a>-->

        <a href="https://www.linkedin.com/in/hu-cao-8084751a3/" target="_blank"><img class="responsive-img social-photo " src="./images/linkedin.png"></a>

        <a href="https://www.researchgate.net/profile/Hu-Cao-3" target="_blank"><img class="responsive-img social-photo " src="./images/rg.png"></a>
    
    </div>    
  
  </div>
  
  <div class="parallax"><img src="./images/homepage_bg_network.jpg" alt="Unsplashed background img 1" style="display: block; transform: translate3d(-50%, 153px, 0px);"></div>  

</div>



<!--==========================================
                   About
===========================================-->
<div class="section about-section scrollspy" id="biography">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title">Biography</div>
      <hr>
    </div>
    
    <div class="row">
      <p>
        I am now a Ph.D. candidate in <a href="https://www.pf.bgu.tum.de/">Chair of Photogrammetrie und Fernerkundung (PF)</a> at
        <a href="https://www.tum.de/en/">Technical University of Munich</a>, supervised and mentored by
        <a href="https://www.pf.bgu.tum.de/en/sta/stilla.html/">Prof. Uwe Stilla</a>,
        <a href="https://vision.in.tum.de/members/cremers/">Prof. Daniel Cremers</a>, and 
        <a href="https://celiang.tongji.edu.cn/info/1300/2743.html/">Prof. Yusheng Xu</a>. 
        Meanwhile, I am a visiting scholar in the Visual Geometry Group (VGG) at the University of Oxford, supervised by Dr. .
        From 2018.03 to 2019.09, I was a research intern at the Robotic and Autonomous Driving Lab (RAL) of Baidu, working with Dr. Xinyu Huang and Prof. Ruigang Yang. I obtained my master’s degree from Xiamen University, supervised by 
        <a href="http://chwang.xmu.edu.cn/index_en.html">Prof. Cheng Wang</a>.
      <!--</p>
      <p>-->
     <!-- </p>
      <p>-->
        My research interests focus on deep representation learning for point clouds, including localization, detection and tracking, shape completion, classsification, and segmentation.
      </p>
      <font color="#0000dd">
      <i>
        I am looking for highly self-motivated collaborators, who are interested in Autonomous Driving and Robotics. Feel free to drop me your up-to-date resume via email.
      </i>
    </font>
  </div>
</div>



<!--==========================================
                   News
===========================================-->
<div class="section news-section scrollspy" id="news">

  <div class="row container">
    <div class="row">
      <div class="title">News</div>
      <hr>
    </div>
    <div class="row">
      <ul>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 10 / 2022: &nbsp; One paper on Efficient-Grasping is accepted by <b>IEEE/ASME Transactions on Mechatronics</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 09 / 2022: &nbsp; Remote visiting the Department of Computer Science, University of Hong Kong, working with <a href="https://scholar.google.com/citations?user=4uE10I0AAAAJ&hl=en">Prof. Hengshuang Zhao</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 09 / 2022: &nbsp; We released a git to collect papers about event-based Robotics (Autonomous Driving & Robotic-Grasping), <a href="https://github.com/HuCaoFighting/Event-based-Vision-for-Robotics">Link</a> <img src="https://img.shields.io/github/stars/HuCaoFighting/Event-based-Vision-for-Robotics?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 08 / 2022: &nbsp; Two papers are accepted by <b>IEEE International Conference on Multisensor Fusion and Integration (MFI), 2022</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 08 / 2022: &nbsp; SwinUnet is accepted by <b>European Conference on Computer Vision-Medical Computer Vision Workshop (ECCV-MCVW), Video is here, <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&list=PLx0njZEDOxbVNpmvpmH6bHjdjmgHKfonr&index=1">Link</a></b>, 2022 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2022: &nbsp; Our paper (Improving Autonomous Driving with Event-Based Neuromorphic Vision) is showcased on IEEE Xplore Innovation Spotlight, which highlights the most innovative and creative research directions, <a href="https://innovate.ieee.org/innovation-spotlight/improving-autonomous-driving-with-event-based-neuromorphic-vision/">Link</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 05 / 2022: &nbsp; One paper on event-based robotic grasping is accepted by <b>IEEE Transactions on Instrumentation and Measurement</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2022: &nbsp; I joined Computer Engineering and Networks Laboratory, <b>ETH Zurich</b>, as an Academic guest, supervised by <a href="https://scholar.google.com/citations?user=OaAKHewAAAAJ&hl=en">Prof. Lothar Thiele</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 09 / 2021: &nbsp; One paper on vehicle detection is accepted by <b>IEEE Sensors Journal</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 05 / 2021: &nbsp; A validation for U-shaped Swin Transformer is published as a Tech Report on Arxiv, Codes released at <a href="https://github.com/HuCaoFighting/Swin-Unet?utm_source=catalyzex.com">SwinUnet</a> <img src="https://img.shields.io/github/stars/HuCaoFighting/Swin-Unet?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2021: &nbsp; Research internship at EI Innovation Lab, Huawei Cloud BU, working with <a href="https://scholar.google.com/citations?user=61b6eYkAAAAJ&hl=zh-CN">Prof. Qi Tian</a> and <a href="https://scholar.google.com/citations?user=Ud6aBAcAAAAJ&hl=zh-CN">Dr. Xiaopeng Zhang</a> and <a href="https://scholar.google.com/citations?user=-eGIgsoAAAAJ&hl=en">Dr. Dongsheng Jiang</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 02 / 2021: &nbsp; One paper on robotic grasping detection is accepted by <b>ICRA 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2020: &nbsp; One paper on parking slot detection is accepted by <b>Frontiers in Neurorobotics</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2020: &nbsp; One paper on event-based vision for robotic grasping is accepted by <b>Frontiers in Neurorobotics</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2020: &nbsp; Our work on event-based vision for autonomous driving is accepted by <b>IEEE SPM (IF 15.204)</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 01 / 2020: &nbsp; I joined the Chair of Robotics, AI and Real-time Systems, <b>TUM</b>, as a Ph.D. student, supervised by <a href="https://www.in.tum.de/i06/people/prof-dr-ing-habil-alois-knoll/">Prof. Alois Knoll</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2019: &nbsp; Our work on event fusion is accepted by <b>Frontiers in Neurorobotics</b> 
        </li>

       <!-- <div align='right'> <a href="./news.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div>-->

      </ul>
    </div>
  </div>
</div>



<!--==========================================
                   Publications
===========================================-->
<div class="section publications-section scrollspy" id="publications">

  <div class="row container">
    <div class="row">
      <div class="title">Publications</div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/EfficientGrasp.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Efficient Grasp Detection Network with Gaussian-based Grasp Representation for Robotic Manipulation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Qian Feng, Jianjie Lin, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE/ASME Transactions on Mechatronics <font color="#0000dd"><b>(Journal, JCR Q1, IF-5.867)</b></font></em>, 2022</div>
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <a href="https://arxiv.org/abs/2101.10226" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2101.10226-B31B1B.svg" /></a>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/swin_block.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Yueyue Wang, Joy Chen, Dongsheng Jiang, Xiaopeng Zhang, Qi Tian, Manning Wang</div>
        <div class="paper-conf"><em>Proceedings of the 17th European Conference on Computer Vision Workshops (ECCVW) <font color="#0000dd"></b></font></em>, 2022</div> 
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <a href="https://arxiv.org/abs/2105.05537" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2105.05537-B31B1B.svg" /></a>
        <!-- </div> -->
        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/Swin-Unet?style=social" />
          <a href="https://github.com/HuCaoFighting/Swin-Unet" target="_blank">[Swin-Unet] </a>
          <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/System_Multimodal4.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">NeuroGrasp: Multi-modal Neural Network with Euler Region Regression for Neuromorphic Vision-based Grasp Pose Estimation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Yingbai Hu, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Instrumentation and Measurement, <font color="#0000dd"><b>(Journal, JCR Q1, IF-5.332)</b></font></em>, 2022</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9787342" target="_blank">[paper]</a>
        </div>

      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/System_Multimodal2.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Fusion-based Feature Attention Gate Component for Vehicle Detection based on Event Camera</div>
          <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Jiahao Xia, Genghang Zhuang, Alois Knoll</div>
          <div class="paper-conf"><em>IEEE Sensors Journal, <font color="#0000dd"><b>(Journal, JCR Q1, IF-4.325)</b></font></em>, 2021</div> 

          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://ieeexplore.ieee.org/abstract/document/9546775" target="_blank">[paper]</a>
          </div>

        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/ResidualGrasp.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Residual Squeeze-and-Excitation Network with Multi-scale Spatial Pyramid Module for Fast Robotic Grasping Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Jianjie Lin, Alois Knoll</div>
          <div class="paper-conf">In <em>Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA) <font color="#0000dd"><b>(ICRA2021, CCF-B)</b></font></em>, Virtual, 2021</div> 
          <div>
            <img class="responsive-img icon" src="./images/pdf.png"> 
            <a href="https://ieeexplore.ieee.org/abstract/document/9561836" target="_blank">[paper] </a>
           <!--  <a href="./files/iccv21_wwt_poster.pdf" target="_blank">[poster]</a> -->
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/parkingslot.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Parking Slot Detection on Around-View Images Using DCNN</div>
          <div class="paper-author"> Wei Li, <font color="#0000dd"><b>Hu Cao*</b></font>, Jiacai Liao, Jiahao Xia, Libo Cao, Alois Knoll</div>
          <div class="paper-conf">In <em>Frontiers in Neurorobotics <font color="#0000dd"><b>(Journal, JCR Q2, IF-3.493)</b></font></em>, 2020</div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2020.00046/full" target="_blank">[paper] </a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/SSD2.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Event-Based Robotic Grasping Detection With Neuromorphic Vision Sensor and Event-Grasping Dataset</div>
          <div class="paper-author"> Bin Li, <font color="#0000dd"><b>Hu Cao*</b></font>, Zhongnan Qu, Yingbai Hu, Zhenke Wang, Zichen Liang</div>
          <div class="paper-conf">In <em>Frontiers in Neurorobotics <font color="#0000dd"><b>(Journal, JCR Q2, IF-3.493)</b></font></em>, 2020</div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2020.00051/full" target="_blank">[paper] </a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/SPM_VIS.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Event-based neuromorphic vision for autonomous driving: a paradigm shift for bio-inspired visual sensing and perception</div>
          <div class="paper-author">Guang Chen, <font color="#0000dd"><b> Hu Cao</b></font>, Jorg Conradt, Huajin Tang, Florian Rohrbein, Alois Knolln</div>
          <div class="paper-conf">IEEE Signal Processing Magazine <font color="#0000dd"><b>(JCR Q1, IF-15.204)</b></font></em>, 2020</div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png"> 
            <a href="https://ieeexplore.ieee.org/abstract/document/9129849" target="_blank">[paper] </a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/pedestrian.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Multi-Cue Event Information Fusion for Pedestrian Detection With Neuromorphic Vision Sensors</div>
          <div class="paper-author"> Guang Chen, <font color="#0000dd"><b>Hu Cao</b></font>, Canbo Ye, Zhenyan Zhang, Xingbo Liu, Xuhui Mo, Zhongnan Qu, Jörg Conradt, Florian Röhrbein, Alois Knoll</div>
          <div class="paper-conf">Frontiers in neurorobotics <font color="#0000dd"><b>(Journal, JCR Q2, IF-3.493)</b></font></em>, 2019</div>

          <div> 
             <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2019.00010/full" target="_blank">[paper]</a> 
          </div> 
          <!-- <div>
            <img class="responsive-img icon" src="./images/pdf.png"> 
            <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2019.00010/full" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1911.08299-B31B1B.svg" /></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/github.png"> 
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RSDet-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/rsdet_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/aaai_2021_qw_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/108185873" target="_blank">[解读]</a>
          </div> -->
        </div>
      </div>
      <!--<div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
  </div>


</div>

<!--==========================================
                   Preprints
===========================================-->
<div class="section preprints-section scrollspy" id="preprints">

  <div class="row container">
    <div class="row">
      <div class="title">Preprints</div>
      <hr>
    </div>

    

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/EfficientGrasp.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Lightweight Convolutional Neural Network with Gaussian-based Grasping Representation for Robotic Grasping Detection</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Qian Feng, Jianjie Lin, Alois Knoll</div>
        <!-- <div class="paper-conf"><em>IEEE Geoscience and Remote Sensing Letters <font color="red"><b>(GRSL, CCF-C)</b></font></em>, 2021</div> -->
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <a href="https://arxiv.org/abs/2101.10226" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2101.10226-B31B1B.svg" /></a>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>

    <hr class="publication-hr">

  </div>

</div>

<!-- ==========================================
                   Activities
=========================================== -->
<div class="section activities-section scrollspy" id="activities">
  <div class="row container">
    <div class="row">
      <div class="title">Academic Activities</div>
      <hr>

        <h5>Conference Reviewers</h5>
        <ul>
          <li>  • AAAI Conference on Artificial Intelligence (AAAI), 2023</li>
          <li>  • European Conference on Computer Vision (ECCV), 2022</li>
          <li>  • IEEE International Conference on Robotics and Automation (ICRA), 2021</li>
          <li>  • IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021</li>
        </ul>

        <h5>Journal Reviewers</h5>
        <ul>
          <li>  • IEEE/ASME Transactions on Mechatronics (T-Mech)</li>
          <li>  • IEEE Transactions on Industrial Electronics (TIE)</li>
          <li>  • IEEE Transactions on Industrial Informatics (TII)</li>
          <li>  • IEEE Transactions on Geoscience and Remote Sensing (TGRS)</li>
          <li>  • IEEE Instrumentation & Measurement Magazine </li>
          <li>  • IEEE Transactions on Medical Imaging (TMI)</li>
          <li>  • Medical Image Analysis</li>
          <li>  • Frontiers in Neurorobotics</li>
          <li>  • Automotive Innovation</li> 
        </ul>

    </div>
  </div>
</div>


<!--==========================================
                   Education
===========================================-->
<!--<div class="section education-section scrollspy" id="education">
  <div class="row container">
    <div class="row">
      <div class="title">Education</div>
      <hr>
    </div>
    
    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.ahut.edu.cn/" target="_blank">
            <img src="./images/ahust.jpg" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>B.E.</b> degree from School of Mechanical Engineering, <a href="https://www.ahut.edu.cn/">Anhui University of Technology</a>, Anhui, China</div>
          <div class="date">Sep. 2013 - July 2017</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.hnu.edu.cn/" target="_blank">
            <img src="./images/HNU.png" style="width:110px;height:110px;" align="center" class="img-responsive edu-img"> -->
            <!-- <img src="./images/iecas.jpeg" style="width:100px;height:100px;" align="center" class="img-responsive edu-img"> -->
            <!-- <img src="./images/air.png" style="width:100px;height:100px;" align="center" class="img-responsive edu-img"> -->
        <!--  </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>M.E.</b> degree from <a href="http://mve.hnu.edu.cn/">College of Mechanical and Vehicle Engineering</a>, <a href="http://dmvb.hnu.edu.cn/index.htm">State key laboratory of advanced design and manufacturing for vehicle body</a> of <a href="https://www.hnu.edu.cn/">HuNan University</a>, HuNan, China</div>
          <div class="date">Sep. 2017 - July 2019</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.tum.de/en/" target="_blank">
            <img src="./images/Tum_logo.gif" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"><b>Ph.D.</b> in <a href="https://www.in.tum.de/i06/home/">Chair of Robotics, AI and Real-time Systems</a>, Department of Informatics</a>, <a href="https://www.tum.de/en/">Technical University of Munich</a>, Munich, Germany</div>
          <div class="date">Jan. 2020 - Present</div>
        </div>
    </div>
  </div>
</div> -->


<div class="section preprints-section scrollspy" id="internship">

  <div class="row container">
    <div class="row">
      <div class="title">Internship and Cooperation</div>
      <hr>
    </div>

        <div class="corp_item">
          <img class="corp_logo" style="height:80px;" src="./images/IIV_TJU2.jfif"> &nbsp; &nbsp;
          <!-- <img class="corp_logo" style="height:80px;" src="./images/megvii.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/tencentmap.png"> &nbsp; &nbsp;-->
          <img class="corp_logo" style="height:80px;" src="./images/huawei1.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:60px;" src="./images/ETH.png">&nbsp; &nbsp;
          <img class="corp_logo" style="height:60px;" src="./images/AG.png">&nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/HKU.png">&nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/fortiss.png">&nbsp; &nbsp;
          <!-- <img class="corp_logo" style="height:80px;" src="./images/bytedance.png"> -->
        </div>

  </div>

</div>


<!-- ==========================================
                   Awards
=========================================== -->
<div class="section awards-section scrollspy" id="awards">
  <div class="row container">
    <div class="row">
      <div class="title">Awards</div>      
      <hr>
      <ul>
        <li>  • Outstanding Graduate of Hunan Province, 2019</li>
        <li>  • Outstanding Graduate of Hunan University, 2019</li>
        <li>  • Outstanding Graduate Student of Hunan University, 2017-2018</li>
        <li>  • Outstanding Graduate Student Leader of Hunan University, 2017-2018</li>
        <li>  • Most media Attention Award, The 3rd Lushan Cup Innovation Challenge Competition, 2018</li>
        <li>  • Second Prize, 2018 ”Haosen Pharmaceutical Cup” 5th China Graduate Smart City Technology and Creative Design Competition , 2018</li>
        <li>  • Second Prize, The 4th National ”TRIZ” Cup College Students Innovation Competition, 2016</li>
        <li>  • First Prize, The 7th National College Students Mechanical Innovation Design Competition, 2016</li>
      </ul>
    </div>
  </div>
</div>

<!-- ==========================================
                   Demo
=========================================== -->
<div class="section awards-section scrollspy" id="demos">
  <div class="row container">
    <div class="row">
      <div class="title">💻 Demos</div>      
      <hr>
      <video width="640" height="360" controls autoplay>
        <source src="./videos/vpc.mp4" type="video/mp4">
      </video>
      <!-- <video width="640" height="360" controls autoplay>
        <source src="./videos/RoboticGraspingMusic.mp4" type="video/mp4">
      </video> -->
      <!-- <img src="https://api.star-history.com/svg?repos=yangxue0827/RotationDetection&type=Date" style="width:600px;" /> -->
      <!-- <img src="https://api.star-history.com/svg?repos=open-mmlab/mmrotate&type=Date" style="width:600px;" /> -->
    </div>
  </div>
</div>

<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer grey lighten-2">
    <div class="row">
      <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
        <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=JmtGDoLvSHQtPqCWd8cr5dhSABXJqV6QbEaaA2Gp1xU'></script> -->
        <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=52alcfaz816&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Copyright © Hu Cao 2021
    </div>  
</footer>

<!--  Scripts-->
<script src="./files/jquery-2.1.1.min.js"></script>
<script src="./files/materialize.js"></script>
<script src="./files/aos.js"></script>
<script src="./init.js"></script>

</div><div class="jvectormap-tip"></div></body></html>
