<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="yanxia">
  <title>Yan Xia's Homepage</title>

  <!-- CSS  -->
  <link href="./files/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./images/TUM_logo3.png">
<script type="text/javascript" src="./files/jquery-1.12.4.min.js.下载"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://Yan-Xia.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://Yan-Xia.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#publications">Publications</a></li>
          <!-- <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#preprints">Preprints</a></li>  -->
          <!--<li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#projects">Projects</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#activities">Activities</a></li>
          <!--<li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#education">Education</a></li>-->
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#internship">Internship</a></li>
          <!-- <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#awards">Awards</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://Yan-Xia.github.io/#demos">Demos</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>
  

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" style="height:280px" src="./images/YanXia.JPG">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name">Dr. Yan Xia </h5>

        <!-- <hr> -->
        <h6 class="profile-link"><strong>Research Scientist at Munich Center for Machine Learning
        <h6 class="profile-link"><strong>Postdoctoral Researcher at Technical University of Munich
        <h6 class="profile-link"><strong>Visiting Scholar in VGG, University of Oxford
        <!-- </strong> <a href="https://www.tum.de/en/"><strong>Chair of Photogrammetrie und Fernerkundung (PF)</strong></a></h6> -->
        <h6 class="profile-link"><strong>Secretary of Working Group I/8 International Society of Photogrammetry and Remote Sensing (ISPRS)
        <!-- <h6 class="profile-link"><strong><a href="https://www.tum.de/en/">Technical University of Munich, Munich, Germany 80333</a></h6> -->
        <h6 class="profile-link"><strong>Email: yan.xia@tum.de</h6>
        
        <h1></h1>
        
        <a href="https://scholar.google.com/citations?user=xkBn4mMAAAAJ&hl=en"><img class="responsive-img social-photo "  src="./images/google_scholar.jpg"></a>
        
        <a href="https://github.com/Yan-Xia/"><img class="responsive-img social-photo " src="./images/github.jpg"></a>

        <!--<a href="./files/HuCao_CV.pdf" target="_blank"><img class="responsive-img social-photo " src="./images/cv.png"></a>-->

        <!--<a href="./images/Wechat_QR_code.jpg" target="_blank"><img class="responsive-img social-photo " src="./images/wechat.png"></a>-->

        <a href="https://linkedin.com/in/yan-xia-tum"><img class="responsive-img social-photo " src="./images/linkedin.png"></a>

        <a href="https://www.researchgate.net/profile/Yan-Xia-20"><img class="responsive-img social-photo "  src="./images/rg.png"></a>
    
    </div>    
  
  </div>
  
  <div class="parallax"><img src="./images/homepage_bg_marienplatz-Chris.jpg" alt="Unsplashed background img 1" style="display: block; opacity: 0.35; transform: translate3d(-50%, 200px, 0px); "></div>  
  <!-- transform: translate3d(-50%, 150px, 0px) -->
</div>



<!--==========================================
                   About
===========================================-->
<div class="section about-section scrollspy" id="biography">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title">Biography</div>
      <hr>
    </div>
    
    <div class="row">
      <p>
        I am now a postdoctoral researcher in the <a href="https://cvg.cit.tum.de/">Computer Vision Group</a> at
        <a href="https://www.tum.de/en/">Technical University of Munich (TUM)</a> working with <a href="https://vision.in.tum.de/members/cremers/">Prof. Daniel Cremers</a>. I am also a research scientist at <a href="https://mcml.ai/">Munich Center for Machine Learning</a>.
         I obtained my phd degree from TUM supervised by <a href="https://www.pf.bgu.tum.de/en/sta/stilla.html/">Prof. Uwe Stilla</a> and <a href="https://vision.in.tum.de/members/cremers/">Prof. Daniel Cremers</a>,
         and was a visiting phd student in the <a href="https://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group (VGG)</a> at University of Oxford working with <a href="https://www.robots.ox.ac.uk/~joao/">Dr. João Henriques</a>. 
         <!-- supervised and mentored by
        <a href="https://www.pf.bgu.tum.de/en/sta/stilla.html/">Prof. Uwe Stilla</a>,
        <a href="https://vision.in.tum.de/members/cremers/">Prof. Daniel Cremers</a>, and 
        <a href="https://celiang.tongji.edu.cn/info/1300/2743.html/">Prof. Yusheng Xu</a>.   -->
        <!-- I am a visiting scholar in the <a href="https://www.robots.ox.ac.uk/~vgg/">Visual Geometry Group (VGG)</a> at <a href="https://www.ox.ac.uk/">University of Oxford</a>, 
        working with  <a href="https://www.robots.ox.ac.uk/~joao/">Dr. João Henriques</a>. -->
        <!-- From 2018.03 to 2018.09, I was a research intern in the Robotic and Autonomous Driving Lab (RAL) of Baidu, working with <a href= "https://scholar.google.com/citations?user=cL4bNBwAAAAJ&hl=en">Dr. Xinyu Huang</a> and <a href= "https://scholar.google.com/citations?user=yveq40QAAAAJ&hl=en">Prof. Ruigang Yang</a>. 
        I obtained my Master's degree on Computer Science from Xiamen University, supervised by <a href="http://chwang.xmu.edu.cn/index_en.html">Prof. Cheng Wang</a>. -->
      <!--</p>
      <p>-->
     <!-- </p> -->
      <!-- <p> -->
        My research interests focus on 3D Vision, Localization and Navigation, Robotics, and Autonomous Driving.
      </p>
      <font color="#0000dd">
      <i>
        I am looking for highly self-motivated and talented Bachelor, Master and PhD students. Feel free to get in touch with me via email If you're interested in collaborating.
      </i>
    </font>
  </div>
</div>



<!--==========================================
                   News
===========================================-->
<div class="section news-section scrollspy" id="news">

  <div class="row container">
    <div class="row">
      <div class="title">News</div>
      <hr>
    </div>
    <div class="row">
      <ul>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 12 / 2024: &nbsp; Our work <a href="https://arxiv.org/pdf/2408.03677">'L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection'</a> is accepted by AAAI 2025!
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 11 / 2024: &nbsp; Our work <a href="https://yunjinli.github.io/projects-vxp/">'VXP: Voxel-Cross-Pixel Large-scale Camera-LiDAR Place Recognition'</a> is accepted by 3DV 2025!
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 11 / 2024: &nbsp; Our work <a href="https://arxiv.org/abs/2411.04865">'ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset'</a> is accepted by WACV 2025!        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2024: &nbsp; Our work <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01900.pdf">'Boosting 3D Single Object Tracking with 2D Matching Distillation and 3D Pre-training'</a> is accepted by ECCV 2024!
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2024: &nbsp; Our work <a href="https://link.springer.com/chapter/10.1007/978-3-031-72907-2_10">'Embracing Events and Frames with Hierarchical Feature Refinement Network for Object Detection'</a> is accepted by ECCV 2024!
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2024: &nbsp; Our work <a href="https://www.ijcai.org/proceedings/2024/72">'Bridging LiDAR Gaps: A Multi-LiDARs Domain Adaptation Dataset for 3D Semantic Segmentation'</a> is accepted by IJCAI 2024!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2024: &nbsp; Our work <a href="https://yan-xia.github.io/projects/text2loc">'Text2Loc: 3D Point Cloud Localization from Natural Language'</a> is accepted by CVPR 2024!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 01 / 2024: &nbsp; Our work <a href="https://ieeexplore.ieee.org/abstract/document/10415359">'OPOCA: One Point One Class Annotation for LiDAR Point Cloud Semantic Segmentation'</a> is accepted by IEEE TGRS!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 10 / 2023: &nbsp; We are organizing a special issue <a href="https://www.mdpi.com/journal/remotesensing/special_issues/5H5UA6M872">'Point Cloud Processing with Machine Learning'</a> on Remote Sensing (SCI, IF 5.0). Welcome to submit your original research work!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 09 / 2023: &nbsp; Our work <a href="https://arxiv.org/pdf/2309.06199.pdf">'SCP: Scene completion pre-training for 3D object detection'</a> wins the <b>best paper award</b> at ISPRS Geospatial Week 2023!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2023: &nbsp; Our work <a href="https://www.robots.ox.ac.uk/~joao/publications/xia_iccv2023.pdf">'CASSPR: Cross Attention Single Scan Place Recognition'</a> is accepted by ICCV 2023!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2023: &nbsp; Our work <a href="https://ieeexplore.ieee.org/abstract/document/10179997">'SegTrans: Semantic Segmentation with Transfer Learning for MLS Point Clouds'</a> is accepted by IEEE GRSL! Congrats, Shuo Shen (MS@TUM)!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2023: &nbsp; Our work <a href="https://openaccess.thecvf.com/content/CVPR2023W/PCV/papers/Wysocki_Scan2LoD3_Reconstructing_Semantic_3D_Building_Models_at_LoD3_Using_Ray_CVPRW_2023_paper.pdf">'Scan2LoD3'</a> on reconstructing semantic 3D building models is accepted by CVPR Workshop 2023!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2023: &nbsp; Our work <a href="https://www.sciencedirect.com/science/article/pii/S0924271623000825">'Fast and deterministic (3+1) DOF point set registration with gravity prior'</a> is accepted by ISPRS Journal!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2023: &nbsp; Passed my PhD with "no corrections"!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 02 / 2023: &nbsp; We are organizing the workshop about <a href="https://gsw2023.com/index.php/project/3ds-smart-cities-3d-sensing-for-smart-cities/">'3DS Smart Cities-3D Sensing for Smart Cities'</a> in the ISPRS Geospatial 
            Week 2023! Welcome to join us!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 01 / 2023: &nbsp; Our work <a href="https://arxiv.org/abs/2203.04232">'DMT'</a> on 3D single object tracking is accepted by IEEE TITS!
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 06 / 2022: &nbsp; I joined Visual Geometry Group (VGG), <b>University of Oxford</b>, as a Visiting Ph.D. student. </a>
        </li>

        <!-- <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2020: &nbsp; Our work on event-based vision for autonomous driving is accepted by <b>IEEE SPM (IF 15.204)</b>
        </li> -->

        <!-- <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 01 / 2020: &nbsp; I joined the Chair of Robotics, AI and Real-time Systems, <b>TUM</b>, as a Ph.D. student, supervised by <a href="https://www.in.tum.de/i06/people/prof-dr-ing-habil-alois-knoll/">Prof. Alois Knoll</a>
        </li> -->

       <!-- <div align='right'> <a href="./news.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->

      </ul>
    </div>
  </div>
</div>



<!--==========================================
                   Publications
===========================================-->
<div class="section publications-section scrollspy" id="publications">

  <div class="row container">
    <div class="row">
      <div class="title">Publications</div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/Text2Loc.png" style="width:300px;height:120px;">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Text2Loc: 3D Point Cloud Localization from Natural Language</div>
        <div class="paper-author"><font color="#0000dd"><b>Yan Xia*&dagger;</b></font>, Letian Shi*, Zifeng Ding, João F. Henriques, Daniel Cremers</div>
        <div class="paper-conf"><em>Conference on Computer Vision and Pattern Recognition (CVPR) <font color="#0000dd"><b></b></font></em>, 2024</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Xia_Text2Loc_3D_Point_Cloud_Localization_from_Natural_Language_CVPR_2024_paper.html" target="_blank">[paper] </a>
        </div>
      </div>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/network_overview.png" style="width:300px;height:120px;">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">SOE-net: A self-attention and orientation encoding network for point cloud based place recognition</div>
        <div class="paper-author"><font color="#0000dd"><b>Yan Xia</b></font>, Yusheng Xu, Shuang Li, Rui Wang, Juan Du, Daniel Cremers, Uwe Stilla</div>
        <div class="paper-conf"><em>Conference on Computer Vision and Pattern Recognition (CVPR) <font color="#0000dd"><b>(Oral)</b></font></em>, 2021</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Xia_SOE-Net_A_Self-Attention_and_Orientation_Encoding_Network_for_Point_Cloud_CVPR_2021_paper.pdf" target="_blank">[paper] </a>
        </div>
      </div>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/CASSPR_overview.png" style="width:300px;height:120px;">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">CASSPR: Cross Attention Single Scan Place Recognition</div>
        <div class="paper-author"><font color="#0000dd"><b>Yan Xia*&dagger;</b></font>, Mariia Gladkova*, Rui Wang, Qianyun Li, Uwe Stilla, João F. Henriques, Daniel Cremers </div>
        <div class="paper-conf"><em>International Conference on Computer Vision (ICCV) <font color="#0000dd"><b></b></font></em>, 2023</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://www.robots.ox.ac.uk/~joao/publications/xia_iccv2023.pdf" target="_blank">[paper] </a>
        </div>
      </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/asfm.png" style="width:300px;height:120px;">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">ASFM-Net: Asymmetrical Siamese Feature Matching Network for Point Completion</div>
          <div class="paper-author"> Yaqi Xia*, <font color="#0000dd"><b>Yan Xia*</b></font>, Wei Li, Rui Song, Kailang Cao, Uwe Stilla (*equal contribution)</div>
          <div class="paper-conf"><em>ACM MM 2021  <font color="#0000dd"><b>(1st place in the leaderboard of Completion3D in April, 2021)</b></font></em>, 2021</div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475348" target="_blank">[paper] </a>
          </div>
        </div>
      </div>


    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/vpc.png" style="width:300px;height:120px;">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">VPC-Net: Completion of 3D Vehicles from MLS Point Clouds</div>
          <div class="paper-author"> <font color="#0000dd"><b>Yan Xia</b></font>, Yusheng Xu, Cheng Wang, Uwe Stilla</div>
          <div class="paper-conf"> <em>ISPRS Journal of Photogrammetry and Remote Sensing <font color="#0000dd"><b>(Top, JCR Q1, IF=11.774)</b></font></em>, 2021</div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271621000344" target="_blank">[paper] </a>
          </div>
        </div>
      </div>


      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/DMT_cover.png" style="width:300px;height:120px;">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">A Lightweight and Detector-free 3D Single Object Tracker on Point Clouds</div>
          <div class="paper-author"> <font color="#0000dd"><b>Yan Xia*&dagger;</b></font>, Qiangqiang Wu*, Wei Li, Antoni B Chan, Uwe Stilla (*equal contribution)</div>
          <div class="paper-conf"> <em>IEEE Transactions on Intelligent Transportation Systems <font color="#0000dd"><b>(Top, JCR Q1, IF=9.551)</b></font></em>, 2023</div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://arxiv.org/abs/2203.04232" target="_blank">[paper] </a>
          </div>
        </div>
      </div>

    <!-- <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/SPM_VIS.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Event-based neuromorphic vision for autonomous driving: a paradigm shift for bio-inspired visual sensing and perception</div>
          <div class="paper-author">Guang Chen, <font color="#0000dd"><b> Hu Cao</b></font>, Jorg Conradt, Huajin Tang, Florian Rohrbein, Alois Knolln</div>
          <div class="paper-conf">IEEE Signal Processing Magazine <font color="#0000dd"><b>(JCR Q1, IF-15.204)</b></font></em>, 2020</div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png"> 
            <a href="https://ieeexplore.ieee.org/abstract/document/9129849" target="_blank">[paper] </a>
          </div>
        </div>
      </div>

      <hr class="publication-hr"> -->

    <!-- <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/pedestrian.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Multi-Cue Event Information Fusion for Pedestrian Detection With Neuromorphic Vision Sensors</div>
          <div class="paper-author"> Guang Chen, <font color="#0000dd"><b>Hu Cao</b></font>, Canbo Ye, Zhenyan Zhang, Xingbo Liu, Xuhui Mo, Zhongnan Qu, Jörg Conradt, Florian Röhrbein, Alois Knoll</div>
          <div class="paper-conf">Frontiers in neurorobotics <font color="#0000dd"><b>(Journal, JCR Q2, IF-3.493)</b></font></em>, 2019</div>

          <div> 
             <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2019.00010/full" target="_blank">[paper]</a> 
          </div>  -->
          <!-- <div>
            <img class="responsive-img icon" src="./images/pdf.png"> 
            <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2019.00010/full" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1911.08299-B31B1B.svg" /></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/github.png"> 
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RSDet-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/rsdet_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/aaai_2021_qw_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/108185873" target="_blank">[解读]</a>
          </div> -->
        </div>
      </div>
      <!--<div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
  </div>


</div>


<!-- ==========================================
                   Activities
=========================================== -->
<div class="section activities-section scrollspy" id="activities">
  <div class="row container">
    <div class="row">
      <div class="title">Academic Services</div>
      <hr>
        <h5>Editor Services</h5>
        <ul>
             Special issue 'Point Cloud Processing with Machine Learning' on Remote Sensing (IF 5.0)
        </ul>

        <h5>Conference Reviewers</h5>
        <ul>
          <li>  • Computer Vision and Pattern Recognition (CVPR), 2022, 2023, 2024, 2025</li>
          <li>  • International Conference on Computer Vision (ICCV), 2023</li>
          <li>  • European Conference on Computer Vision (ECCV), 2022, 2024 </li>
          <li>  • Neural Information Processing Systems (NeurIPS), 2023</li>
          <li>  • ACM Multimedia (MM), 2024</li>
          <li>  • International Joint Conference on Artificial Intelligence (IJCAI), 2024</li>
          <li>  • Asian Conference on Computer Vision (ACCV), 2024</li>
          <!-- <li>  • Computer Vision and Pattern Recognition (CVPR), 2024</li> -->
          <!-- <li>  • Computer Vision and Pattern Recognition (CVPR), 2023</li> -->
          <!-- <li>  • Computer Vision and Pattern Recognition (CVPR), 2022</li> -->
          <!-- <li>  • European Conference on Computer Vision (ECCV), 2022</li> -->
        </ul>

        <h5>Journal Reviewers</h5>
        <ul>
          <li>  • IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</li>
          <li>  • IEEE Transactions on Image Processing (T-IP)</li>
          <li>  • ISPRS Journal of Photogrammetry and Remote Sensing (ISPRS-J)
          <li>  • IEEE Transactions on Intelligent Transportation Systems (T-ITS)</li>
          <li>  • IEEE Transactions on Visualization and Computer Graphics (T-VCG)</li>
          <li>  • IEEE Transactions on Geoscience and Remote Sensing (T-GRS)</li>
          <li>  • IEEE Transactions on Intelligent Vehicles (T-IV)</li>          
          <li>  • Pattern Reccognition (PR) </li>
        </ul>

    </div>
  </div>
</div>


<!--==========================================
                   Education
===========================================-->
<!--<div class="section education-section scrollspy" id="education">
  <div class="row container">
    <div class="row">
      <div class="title">Education</div>
      <hr>
    </div>
    
    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.ahut.edu.cn/" target="_blank">
            <img src="./images/ahust.jpg" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>B.E.</b> degree from School of Mechanical Engineering, <a href="https://www.ahut.edu.cn/">Anhui University of Technology</a>, Anhui, China</div>
          <div class="date">Sep. 2013 - July 2017</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.hnu.edu.cn/" target="_blank">
            <img src="./images/HNU.png" style="width:110px;height:110px;" align="center" class="img-responsive edu-img"> -->
            <!-- <img src="./images/iecas.jpeg" style="width:100px;height:100px;" align="center" class="img-responsive edu-img"> -->
            <!-- <img src="./images/air.png" style="width:100px;height:100px;" align="center" class="img-responsive edu-img"> -->
        <!--  </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>M.E.</b> degree from <a href="http://mve.hnu.edu.cn/">College of Mechanical and Vehicle Engineering</a>, <a href="http://dmvb.hnu.edu.cn/index.htm">State key laboratory of advanced design and manufacturing for vehicle body</a> of <a href="https://www.hnu.edu.cn/">HuNan University</a>, HuNan, China</div>
          <div class="date">Sep. 2017 - July 2019</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.tum.de/en/" target="_blank">
            <img src="./images/Tum_logo.gif" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"><b>Ph.D.</b> in <a href="https://www.in.tum.de/i06/home/">Chair of Robotics, AI and Real-time Systems</a>, Department of Informatics</a>, <a href="https://www.tum.de/en/">Technical University of Munich</a>, Munich, Germany</div>
          <div class="date">Jan. 2020 - Present</div>
        </div>
    </div>
  </div>
</div> -->


<div class="section preprints-section scrollspy" id="internship">

  <div class="row container">
    <div class="row">
      <div class="title">Internship and Cooperation</div>
      <hr>
    </div>

        <div class="corp_item">
          <img class="corp_logo" style="height:80px;" src="./images/microsoft.png"> &nbsp; &nbsp;
          <!-- <img class="corp_logo" style="height:80px;" src="./images/megvii.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/tencentmap.png"> &nbsp; &nbsp;-->
          <img class="corp_logo" style="height:80px;" src="./images/baidu.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/mechmind.png">&nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/inceptio.png">&nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/oxford.png">&nbsp; &nbsp;
          <!-- <img class="corp_logo" style="height:80px;" src="./images/fortiss.png">&nbsp; &nbsp; -->
          <!-- <img class="corp_logo" style="height:80px;" src="./images/bytedance.png"> -->
        </div>

  </div>

</div>

<!-- ==========================================
                   Demo
=========================================== -->
<div class="section awards-section scrollspy" id="demos">
  <div class="row container">
    <div class="row">
      <div class="title">💻 Demos</div>      
      <hr>
      <video width="640" height="360" controls autoplay>
        <source src="./videos/vpc.mp4" type="video/mp4">
      </video>
      <!-- <video width="640" height="360" controls autoplay>
        <source src="./videos/RoboticGraspingMusic.mp4" type="video/mp4">
      </video> -->
      <!-- <img src="https://api.star-history.com/svg?repos=yangxue0827/RotationDetection&type=Date" style="width:600px;" /> -->
      <!-- <img src="https://api.star-history.com/svg?repos=open-mmlab/mmrotate&type=Date" style="width:600px;" /> -->
    </div>
  </div>
</div>



<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer grey lighten-2">
    <div class="row">
      <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
        <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=JmtGDoLvSHQtPqCWd8cr5dhSABXJqV6QbEaaA2Gp1xU'></script> -->
        <!-- <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=52alcfaz816&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script> -->
        <!-- <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=52alcfaz816&amp;m=1&amp;c=ff007e&amp;cr1=ffffff&amp;f=arial&amp;l=33&amp;bv=5" async="async"></script> -->
        <!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=WZiQDjEBsbIqdM9REi8r4vlsncoMqKoPdcGbWIQGBRs"></script> -->
        <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=WZiQDjEBsbIqdM9REi8r4vlsncoMqKoPdcGbWIQGBRs&cl=ffffff&w=a"></script> -->
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=WZiQDjEBsbIqdM9REi8r4vlsncoMqKoPdcGbWIQGBRs&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Copyright © Yan Xia 2022
    </div>  
</footer>

<!--  Scripts-->
<script src="./files/jquery-2.1.1.min.js"></script>
<script src="./files/materialize.js"></script>
<script src="./files/aos.js"></script>
<script src="./init.js"></script>

</div><div class="jvectormap-tip"></div></body></html>
